---
title: "Thinking Alike"
summary: "Exploring the similarities between human thinking and machine learning models."
date: "2025-10-10"
readTime: "5 min"
image: "blog-thinking-alike"
featured: true
tags: ["Machine Learning", "Neuroscience", "Philosophy"]
---

We often think of machine learning models as clinical, mathematical artifacts that ingest data and return an output. But if you look closer, you come to realize that
these models learn, adapt, form biases, and even forget. In other words, they behave a lot like humans. Machine learning is, in many ways, a digital reflection of how
humans perceive, process, and change through experience. Understanding the anatomy of a model can reveal not only how machines think, but also the core mechanisms behind
how we do.

## Inputs as Perception

Every human experience begins with perception. We are exposed to stimuli through the senses, which our brain translates into understanding. A machine learning model does
the same, except its "senses" are numerical values instead of neurons. It receives structured data that represents aspects of its world — known as **input features**.

But perception, human and machine alike, is fragile. Feed a model noisy or biased data, and it builds a distorted view of reality. Through no fault of the machine, our own
understanding of reality is also shaped and limited by the quality and diversity of our experiences.

## Neural Architecture

Beneath perception lies the structure that transforms sensation into meaning. For humans, this structure is our brain's neural architecture — billions of interconnected
neurons forming pathways that mold our thoughts and memories. For machine learning models, it's a designed pattern of **layers** and **nodes** that determines how information moves
and transforms.

![The architecture of a ML model](/src/assets/thinking-alike/1.jpg)

Every connection between nodes has a **weight**, just as every belief has a strength. These weights, or **parameters**, are adjusted as the model learns, emphasizing patterns that
matter and discounting those that don't. Over time, these weights form the model's "understanding" of its world. Much like us, that understanding is not innate but learned
through countless experiences.

## Feedback and Growth

Learning is not possible without feedback. Each time we act, our minds register a response that grades the outcome. In machine learning, this mechanism is represented by
the **loss function** — a numerical measure of how wrong a model's output is.

![Loss minimization within an optimization space](/src/assets/thinking-alike/2.jpg)

The **optimizer** allows models to reflect and adapt. Computationally equivalent to how humans learn, it takes feedback from the loss function and adjusts the model's weights
to minimize error. Humans optimize too — we refine our habits, adjust our beliefs, and slowly become better versions of ourselves through correction and reflection.

## Learning Temperament

Two people exposed to the same environment don't automatically learn in the same way. One might learn quickly but be swayed by every new idea, while another might learn more
slowly but build a steadier foundation. Machine learning manages this individuality through **hyperparameters** — the qualities that dictate a model's learning style.

Learning rate, batch size, depth, and regularization all have parallels to the speed, volume, depth, and consistency of the information we can process. Akin to temperament,
these traits aren't learned but intrinsic — shaping how each of us approaches learning itself.

## The Human Condition

No model, nor human, is without flaws. Some adapt to their inputs too well — memorizing rather than generalizing — a problem known as **overfitting**. Humans do this too: we
overlearn from specific experiences and misapply them in new contexts. Culture shock, for instance, is a kind of overfitting — our expectations, tuned to one environment,
fail to generalize to another.

![Appropriate and over-fitting of available data](/src/assets/thinking-alike/3.jpg)

Models need **regularization** — constraints that help them generalize beyond what they've been exposed to. Humans need something similar, whether it's humility, introspection,
or openness to new ideas. Without it, both models and people become too rigid in their experiences to offer value outside of them.

## Evaluation

When training ends, a model's performance is tested on data it has never seen before. This stage reveals whether the model has truly learned or merely memorized. Success
here means it can apply its understanding to new and unfamiliar examples — the true measure of intelligence in both machines and people.

In our own lives, every new situation, conversation, or challenge asks us to generalize from what we've experienced before. Growth isn't proven in familiar environments or
tasks; it's revealed when we meet an unfamiliar problem with understanding instead of repetition. True learning isn't measured by what we can recall from memory, but by how
fluently we can apply what we know in a new context.

## The Learning Loop

Learning never truly ends — for models or for humans. In production, a model must be monitored, retrained, and updated as new data is collected. The environment it was
built to represent keeps changing, and if the model stands still, it drifts away from relevance.

![The learning loop](/src/assets/thinking-alike/4.jpg)

The same is true for us. We learn through continual reflection, application, and feedback. Our understanding must be retrained by new experiences; our assumptions must
be challenged by fresh perspectives. A model that isn't retrained grows obsolete. A person who stops learning becomes disconnected.

## Our Reflection

When we look closely at the anatomy of a machine learning model, we're inevitably presented with a mirror — one that reflects not just how machines learn, but how we do.
We can see that experience shapes understanding, error drives growth, and change is continuous. The systems we've built are less foreign than we imagine; they are
reflections of our own cognitive architecture.

At its core, machine learning is simply another example of how anything — given enough information and feedback — comes to know the world.
